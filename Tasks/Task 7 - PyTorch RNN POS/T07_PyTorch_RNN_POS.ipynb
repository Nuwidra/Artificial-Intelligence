{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehUxc7AtDfU5"
      },
      "source": [
        "### ITCR - Escuela de Computación\n",
        "### Curso IC-6200 - Inteligencia Artificial\n",
        "### Aprendizaje supervisado\n",
        "\n",
        "### Redes de memoria de corto y largo plazo con PyTorch \n",
        "### (Long-Short Term Memory Networks-LSTM)\n",
        "\n",
        "**Profesora: María Auxiliadora Mora**\n",
        "\n",
        "**Estudiantes:**\n",
        "- Jonathan Quesada Salas\n",
        "- Rodolfo Cruz Vega"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyr84u8ab1kw"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "La clasificación de textos y el reconocimiento de entidades nombradas (Named Entity Recognition o NER por sus siglas en inglés) son técnicas fundamentales que constituyen el primer paso en muchas tareas de Procesamiento de lenguaje natural (NLP). NER, es un área de investigación relacionada a la extracción de información, que permite localizar y clasificar nombres de entidades que se encuentran en texto libre, en categorías comunmente organizaciones, lugares, tiempo, personas, entre otros. Ejemplo:\n",
        "\n",
        "- El fundador de [Microsoft Corporation] (organización), [Bill Gates] (persona), comentó que se abrirán 1000 puestos de trabajo en la [Región Chorotega] (lugar) a partir del año 2022 (fecha).  \n",
        "\n",
        "La clasificación de textos permite categorizar el contenido asociando este a un conjunto de etiquetas predefinidas o clases. Su uso más popular es el análisis de sentimientos. Ejemplo:\n",
        "\n",
        "- En mi opinión, la película fue muy buena porque pudo dar a conocer a los espectadores cómo puede afectar una situación traumática a la mente humana. (Clase = 5 o excelente). \n",
        "\n",
        "Las redes neuronales recurrentes o RNN (Rumelhart et al., 1986, como se citó en LeCun et al., 2015) son una familia de redes neuronales para el procesamiento de secuencias de datos, las cuales en un tiempo t, reciben el estado anterior, es decir, su salida en el tiempo t podría usarse como insumo del procesamiento de la siguiente entrada, de modo que la información pueda propagarse a medida que la red pasa por la secuencia de entrada. Las redes Long Short-Term Memory (LSTM) son un tipo de red neuronal recurrente capaz de aprender dependencias a largo plazo.\n",
        "\n",
        "El siguiente ejemplo implementa NER con una LSTM para etiquetar el rol que juegan las palabras en las oraciones. \n",
        "\n",
        "\n",
        "## Ejemplo\n",
        "\n",
        "El sistema implementado en el código adjunto soluciona el problema de estimar el rol de una palabra en una frase, por ejempo roles como determinante (DET), nombre (NN) y verbo (V). \n",
        "Ejemplo para la frase:\n",
        "\n",
        "- \"El perro come manzana\" la salida deberá ser: [\"DET\", \"NN\", \"V\", \"NN\"]). \n",
        "\n",
        "Este proceso se conoce en el procesamiento de lenguaje natural como \"part of speech tagging (POS)\".\n",
        "\n",
        "Este es un ejemplo simple con datos introducidos en el código basado en [1].\n",
        "\n",
        "Se realizarán los siguientes pasos\n",
        "\n",
        "   * Definición de los ejemplos (codificados) \n",
        "   * Preprocesamiento de las palabras a clasificar\n",
        "   * Definición del modelo\n",
        "   * Instanciación del modelo, definición de la función de pérdida y del optimizador  \n",
        "   * Entrenamiento de la red\n",
        "   * Pruebas del modelo resultante con unos cuantos ejemplos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmqx6kMSDfU9",
        "outputId": "861acca2-d46e-4dfd-9fb1-c06ea9293553"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa26d266df0>"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ],
      "source": [
        "# Bibliotecas requeridas\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import csv\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsFmju8xDfVQ"
      },
      "outputs": [],
      "source": [
        "# Funciones utilitarias\n",
        "\n",
        "def max_values(x):\n",
        "    \"\"\"\n",
        "    Retorna el valor máximo y en índice o la posición del valor en un vector x.\n",
        "    Parámetros: \n",
        "        x: vector con los datos. \n",
        "    Salida: \n",
        "        out: valor \n",
        "        inds: índice\n",
        "    \"\"\"\n",
        "    out, inds = torch.max(x,dim=1)   \n",
        "    return out, inds\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Leer los datos del archivo CSV\n",
        "data = pd.read_csv('datos.csv', encoding=\"utf-8\")\n",
        "\n",
        "# Convertir las columnas en listas de Python\n",
        "sentences = data['sentence'].tolist()\n",
        "tags = data['tags'].tolist()\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "train_sentences, test_sentences, train_tags, test_tags = train_test_split(sentences, tags, test_size=0.2, random_state=42)\n",
        "\n",
        "# Mostrar los tamaños de los conjuntos de datos resultantes\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", len(train_sentences))\n",
        "print(\"Tamaño del conjunto de prueba:\", len(test_sentences))\n",
        "\n",
        "print(train_sentences[0])\n",
        "print(train_tags[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKw2UfyGNuIO",
        "outputId": "7bcb09cf-d30d-4daa-fe5c-93e820b6fcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 40\n",
            "Tamaño del conjunto de prueba: 10\n",
            "El agua fría refresca\n",
            "DET NN ADJ V\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IauAgJYkDfVb",
        "outputId": "ea7ef36a-f517-4bb5-8c4e-a728efdf4892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diccionario {'El': 0, 'agua': 1, 'fría': 2, 'refresca': 3, 'La': 4, 'flor': 5, 'marchita': 6, 'está': 7, 'triste': 8, 'lluvia': 9, 'suave': 10, 'cae': 11, 'sobre': 12, 'el': 13, 'suelo': 14, 'árbol': 15, 'frondoso': 16, 'da': 17, 'sombra': 18, 'hombre': 19, 'cansado': 20, 'corre': 21, 'rápidamente': 22, 'casa': 23, 'grande': 24, 'es': 25, 'hermosa': 26, 'serpiente': 27, 'sigilosa': 28, 'se': 29, 'arrastra': 30, 'silenciosamente': 31, 'sol': 32, 'caliente': 33, 'calienta': 34, 'día': 35, 'de': 36, 'verano': 37, 'puerta': 38, 'abierta': 39, 'par': 40, 'en': 41, 'invita': 42, 'a': 43, 'entrar': 44, 'mujer': 45, 'elegante': 46, 'camina': 47, 'lentamente': 48, 'brillante': 49, 'ilumina': 50, 'perro': 51, 'ruidoso': 52, 'ladra': 53, 'sin': 54, 'parar': 55, 'comida': 56, 'deliciosa': 57, 'hace': 58, 'la': 59, 'boca': 60, 'niño': 61, 'estudioso': 62, 'concentra': 63, 'sus': 64, 'tareas': 65, 'bebé': 66, 'travieso': 67, 'gatea': 68, 'gato': 69, 'negro': 70, 'duerme': 71, 'plácidamente': 72, 'emocionado': 73, 'salta': 74, 'con': 75, 'alegría': 76, 'habla': 77, 'voz': 78, 'alta': 79, 'ventana': 80, 'permite': 81, 'ver': 82, 'afuera': 83, 'llora': 84, 'desconsoladamente': 85, 'vaso': 86, 'vacío': 87, 'mesa': 88, 'viento': 89, 'fuerte': 90, 'sopla': 91, 'cesar': 92, 'lápiz': 93, 'afilado': 94, 'dibuja': 95, 'líneas': 96, 'precisas': 97, 'niña': 98, 'pequeña': 99, 'juega': 100, 'felizmente': 101, 'silla': 102, 'rota': 103, 'no': 104, 'puede': 105, 'usar': 106, 'libro': 107, 'viejo': 108, 'abierto': 109, 'pelota': 110, 'desinflada': 111, 'rebota': 112, 'playa': 113, 'desierta': 114, 'tranquilidad': 115, 'tren': 116, 'veloz': 117, 'pasa': 118, 'teléfono': 119, 'insistente': 120, 'suena': 121, 'constantemente': 122, 'cerrada': 123, 'bloqueada': 124, 'ave': 125, 'libre': 126, 'vuela': 127, 'por': 128, 'cielo': 129, 'montaña': 130, 'imponente': 131, 'majestuosa': 132, 'luna': 133, 'brilla': 134, 'nocturno': 135, 'tierno': 136, 'sonríe': 137, 'adorablemente': 138, 'coche': 139, 'rápido': 140, 'va': 141, 'carretera': 142, 'balón': 143, 'redondo': 144, 'chocolate': 145, 'derretido': 146, 'delicioso': 147, 'luz': 148, 'encendida': 149, 'vendedor': 150, 'amable': 151, 'ofrece': 152, 'ayuda': 153, 'los': 154, 'clientes': 155, 'pájaro': 156, 'alegre': 157, 'canta': 158, 'melodías': 159, 'hermosas': 160, 'nube': 161, 'blanca': 162, 'flota': 163, 'azul': 164, 'música': 165, 'relajante': 166, 'pared': 167, 'pintada': 168, 'precisión': 169, 'fuego': 170, 'ardiente': 171, 'quema': 172, 'madera': 173, 'juguetón': 174, 'persigue': 175, 'al': 176, 'velozmente': 177, 'jardín': 178, 'hermoso': 179, 'lleno': 180, 'flores': 181, 'reloj': 182, 'antiguo': 183, 'marca': 184, 'hora': 185, 'correctamente': 186, 'radiante': 187, 'pone': 188, 'horizonte': 189, 'río': 190, 'tranquilo': 191, 'fluye': 192, 'prisa': 193}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv\n",
        "\n",
        "# Leer los datos del archivo CSV\n",
        "data = pd.read_csv('datos.csv', encoding=\"utf-8\")\n",
        "\n",
        "# Convertir las columnas en listas de Python\n",
        "sentences = data['sentence'].tolist()\n",
        "tags = data['tags'].tolist()\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "train_sentences, test_sentences, train_tags, test_tags = train_test_split(sentences, tags, test_size=0.2, random_state=42)\n",
        "\n",
        "# Frases de entrenamiento \n",
        "# El modelo solo va a aprender a identificar DET, NN, V \n",
        "training_data = []\n",
        "for i in range(len(train_sentences)):\n",
        "    training_data.append((train_sentences[i].split(), train_tags[i].split()))\n",
        "\n",
        "# Datos de prueba\n",
        "test_data = []\n",
        "for i in range(len(test_sentences)):\n",
        "    test_data.append((test_sentences[i].split(), test_tags[i].split()))\n",
        "\n",
        "# Diccionario las palabras\n",
        "word_to_ix = {}\n",
        "for sent, tags in training_data + test_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "            \n",
        "print(\"Diccionario\", word_to_ix)\n",
        "\n",
        "# Asignar índices a las etiquetas\n",
        "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2, \"ADJ\": 3}\n",
        "\n",
        "\n",
        "# Preparación de los datos \n",
        "def prepare_sequence(seq, to_ix):\n",
        "    \"\"\"\n",
        "    Retorna un tensor con los indices del diccionario para cada palabras en una oración.\n",
        "    Parámetros:\n",
        "       seq: oración\n",
        "       to_ix: diccionario de palabras.\n",
        "    \"\"\"\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbTNyN4_4CXZ",
        "outputId": "141777c4-01aa-45fb-a5df-8cf444e234dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['El', 'agua', 'fría', 'refresca']\n",
            "tensor([0, 1, 2, 3])\n",
            "[(['El', 'agua', 'fría', 'refresca'], ['DET', 'NN', 'ADJ', 'V']), (['La', 'flor', 'marchita', 'está', 'triste'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['La', 'lluvia', 'suave', 'cae', 'sobre', 'el', 'suelo'], ['DET', 'NN', 'ADJ', 'V', 'NN', 'DET', 'NN']), (['El', 'árbol', 'frondoso', 'da', 'sombra'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['El', 'hombre', 'cansado', 'corre', 'rápidamente'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['La', 'casa', 'grande', 'es', 'hermosa'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['La', 'serpiente', 'sigilosa', 'se', 'arrastra', 'silenciosamente'], ['DET', 'NN', 'ADJ', 'DET', 'V', 'ADJ']), (['El', 'sol', 'caliente', 'calienta', 'el', 'día', 'de', 'verano'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'NN', 'DET', 'NN']), (['La', 'puerta', 'abierta', 'de', 'par', 'en', 'par', 'invita', 'a', 'entrar'], ['DET', 'NN', 'ADJ', 'V', 'NN', 'V', 'NN', 'V', 'DET', 'V']), (['La', 'mujer', 'elegante', 'camina', 'lentamente'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['El', 'sol', 'brillante', 'ilumina', 'el', 'día'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'NN']), (['El', 'perro', 'ruidoso', 'ladra', 'sin', 'parar'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'ADJ']), (['La', 'comida', 'deliciosa', 'hace', 'agua', 'la', 'boca'], ['DET', 'NN', 'ADJ', 'V', 'NN', 'DET', 'ADJ']), (['El', 'niño', 'estudioso', 'se', 'concentra', 'en', 'sus', 'tareas'], ['DET', 'NN', 'ADJ', 'V', 'ADJ', 'DET', 'DET', 'NN']), (['El', 'bebé', 'travieso', 'gatea', 'rápidamente'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['El', 'gato', 'negro', 'duerme', 'plácidamente'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['El', 'niño', 'emocionado', 'salta', 'con', 'alegría'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'ADJ']), (['El', 'hombre', 'habla', 'en', 'voz', 'alta'], ['DET', 'NN', 'V', 'DET', 'NN', 'ADJ']), (['La', 'ventana', 'abierta', 'permite', 'ver', 'afuera'], ['DET', 'NN', 'ADJ', 'V', 'V', 'NN']), (['El', 'niño', 'llora', 'desconsoladamente'], ['DET', 'NN', 'V', 'ADJ']), (['El', 'vaso', 'vacío', 'está', 'sobre', 'la', 'mesa'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'DET', 'NN']), (['El', 'viento', 'fuerte', 'sopla', 'sin', 'cesar'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'NN']), (['El', 'lápiz', 'afilado', 'dibuja', 'líneas', 'precisas'], ['DET', 'NN', 'ADJ', 'V', 'NN', 'ADJ']), (['La', 'niña', 'pequeña', 'juega', 'felizmente'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['La', 'silla', 'rota', 'no', 'se', 'puede', 'usar'], ['DET', 'NN', 'DET', 'V', 'DET', 'DET', 'V']), (['El', 'libro', 'viejo', 'está', 'abierto'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['La', 'pelota', 'desinflada', 'no', 'rebota'], ['DET', 'NN', 'ADJ', 'V', 'NN']), (['La', 'playa', 'desierta', 'invita', 'a', 'la', 'tranquilidad'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'DET', 'ADJ']), (['El', 'tren', 'veloz', 'pasa', 'rápidamente'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['El', 'teléfono', 'insistente', 'suena', 'constantemente'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['La', 'puerta', 'cerrada', 'está', 'bloqueada'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['El', 'ave', 'libre', 'vuela', 'por', 'el', 'cielo'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'DET', 'NN']), (['La', 'montaña', 'imponente', 'es', 'majestuosa'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['La', 'luna', 'brillante', 'brilla', 'en', 'el', 'cielo', 'nocturno'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'DET', 'NN', 'ADJ']), (['El', 'bebé', 'tierno', 'sonríe', 'adorablemente'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['El', 'coche', 'rápido', 'va', 'por', 'la', 'carretera'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'DET', 'NN']), (['El', 'balón', 'redondo', 'rebota', 'en', 'el', 'suelo'], ['DET', 'NN', 'ADJ', 'V', 'DET', 'DET', 'NN']), (['El', 'chocolate', 'derretido', 'es', 'delicioso'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['La', 'luz', 'brillante', 'está', 'encendida'], ['DET', 'NN', 'ADJ', 'V', 'ADJ']), (['El', 'vendedor', 'amable', 'ofrece', 'ayuda', 'a', 'los', 'clientes'], ['DET', 'NN', 'ADJ', 'V', 'V', 'DET', 'DET', 'NN'])]\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de procesamiento de una oración\n",
        "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "print(training_data[0][0])                          \n",
        "print(inputs)\n",
        "\n",
        "print(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLmaT08_DfVm"
      },
      "outputs": [],
      "source": [
        "# Definición del modelo\n",
        "\n",
        "# El modelo es una clase que debe heredar de nn.Module\n",
        "class LSTMTagger(nn.Module):\n",
        "    \"\"\"\n",
        "    Clase para aplicar POST a oraciones en español. \n",
        "    \"\"\"\n",
        "    \n",
        "    # Incialización del modelo\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        \"\"\"\n",
        "        Inicialización de la clase.\n",
        "        Parámetros:\n",
        "           embedding_dim: dimesionalidad del vector de palabras. \n",
        "           hidden_dim: dimensión de la capa oculta de la red. \n",
        "           vocab_size: tamaño del vocabulario.  \n",
        "           tagset_size: número de clases.\n",
        "        \"\"\"\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Primero se pasa la entrada a través de una capa Embedding. \n",
        "        # Esta capa construye una representación de los tokens de \n",
        "        # un texto donde las palabras que tienen el mismo significado \n",
        "        # tienen una representación similar.\n",
        "        \n",
        "        # Esta capa captura mejor el contexto y son espacialmente \n",
        "        # más eficientes que las representaciones vectoriales (one-hot vector).\n",
        "        # En Pytorch, se usa el módulo nn.Embedding para crear esta capa, \n",
        "        # que toma el tamaño del vocabulario y la longitud deseada del vector \n",
        "        # de palabras como entrada. Ejemplos en [3] y [4]\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # El LSTM toma word_embeddings como entrada y genera los estados ocultos\n",
        "        # con dimensionalidad hidden_dim.  \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # La capa lineal mapea el espacio de estado oculto \n",
        "        # al espacio de clases\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        # Pasada hacia adelante de la red. \n",
        "        # Parámetros:\n",
        "        #    sentence: la oración a procesar\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "\n",
        "        # Se utiliza softmax para devolver la probabilidad de cada etiqueta\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHhOk08h1qY2"
      },
      "outputs": [],
      "source": [
        "# Instanciación del modelo, definición de la función de pérdida y del optimizador   \n",
        "\n",
        "# Hiperparámetros de la red\n",
        "# Valores generalmente altos (32 o 64 dimensiones).\n",
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6\n",
        "\n",
        "# Instancia del modelo\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "\n",
        "# Función de pérdida: Negative Log Likelihood Loss (NLLL). \n",
        "# Generalmente utilizada en problemas de clasificacion con múltiples clases.\n",
        "loss_function = nn.NLLLoss()\n",
        "\n",
        "# Optimizador Stochastic Gradient Descent  \n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRYCyKy-DfVu",
        "outputId": "4be1359b-c3f1-4fb6-81b5-2dd3e764f71f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['El', 'agua', 'fría', 'refresca']\n",
            "tensor([[-1.1945, -1.2007, -1.7257, -1.5228],\n",
            "        [-1.1901, -1.2156, -1.7265, -1.5079],\n",
            "        [-1.2055, -1.1415, -1.7726, -1.5549],\n",
            "        [-1.1728, -1.2043, -1.7058, -1.5655]])\n",
            "Resultados luego del entrenamiento para la primera frase\n",
            "tensor([[-9.4977e-04, -6.9671e+00, -1.1981e+01, -1.4436e+01],\n",
            "        [-1.3121e+01, -2.7403e-03, -1.8587e+01, -5.9018e+00],\n",
            "        [-7.0993e+00, -7.7049e+00, -7.4247e+00, -1.8744e-03],\n",
            "        [-8.2136e+00, -1.4277e+01, -4.1257e-03, -5.5609e+00]])\n"
          ]
        }
      ],
      "source": [
        "# Entrenamiento del modelo \n",
        "\n",
        "# Valores antes de entrenar\n",
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    tag_scores = model(inputs)\n",
        "    \n",
        "    print(training_data[0][0])\n",
        "    \n",
        "    # Clasificación    \n",
        "    print(tag_scores)\n",
        "\n",
        "# Épocas de entrenamiento\n",
        "for epoch in range(200):  \n",
        "    for sentence, tags in training_data:\n",
        "        ## Paso 1. Pytorch acumula los gradientes.\n",
        "        # Es necesario limpiarlos\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Paso 2. Se preparan las entradas, es decir, se convierten a\n",
        "        # tensores de índices de palabras.\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "        # Paso 3. Se genera la predicción (forward pass).\n",
        "        tag_scores = model(sentence_in)\n",
        "\n",
        "        # Paso 4. se calcula la pérdida, los gradientes, y se actualizan los \n",
        "        # parámetros por medio del optimizador.\n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Despligue de la puntuación luego del entrenamiento\n",
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    tag_scores = model(inputs)\n",
        "   \n",
        "    print(\"Resultados luego del entrenamiento para la primera frase\")\n",
        "    # Las palabras en una oración se pueden etiquetar de tres formas.\n",
        "    # La primera oración tiene 4 palabras \"El perro come manzana\"\n",
        "    # por eso el tensor de salida tiene 4 elementos. \n",
        "    # Cada elemento es un vector de pesos que indica cuál etiqueta tiene más\n",
        "    # posibilidad de estar asociada a la palabra. Es decir hay que calcular \n",
        "    # la posición del valor máximo\n",
        "    print(tag_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPj6v4tsDfV2",
        "outputId": "31bad709-5957-42eb-aee4-1b8e5a1b0b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases\n",
            "{'DET': 0, 'NN': 1, 'V': 2, 'ADJ': 3}\n",
            "FRASE\n",
            "La frase original ['El', 'pájaro', 'alegre', 'canta', 'melodías', 'hermosas']\n",
            "La frase original preprocesada tensor([  0, 156, 157, 158, 159, 160])\n",
            "Salida del modelo tensor([[-9.4977e-04, -6.9671e+00, -1.1981e+01, -1.4436e+01],\n",
            "        [-1.2067e+01, -1.1533e-03, -1.8914e+01, -6.7707e+00],\n",
            "        [-9.3166e+00, -4.7764e+00, -7.2982e+00, -9.2352e-03],\n",
            "        [-1.2215e+01, -9.4336e+00, -1.4378e-01, -2.0111e+00],\n",
            "        [-6.3779e+00, -5.5018e+00, -3.4360e+00, -3.8710e-02],\n",
            "        [-6.1086e+00, -9.4115e+00, -5.6043e+00, -6.0057e-03]])\n",
            "Valores máximos e índices (tensor([-0.0009, -0.0012, -0.0092, -0.1438, -0.0387, -0.0060]), tensor([0, 1, 3, 2, 3, 3]))\n"
          ]
        }
      ],
      "source": [
        "# Uso del modelo generado\n",
        "\n",
        "def test_examples(test_data):\n",
        "\n",
        "   with torch.no_grad():\n",
        "      inputs = prepare_sequence(test_data, word_to_ix)\n",
        "      tag_scores = model(inputs)\n",
        "    \n",
        "   # Se imprime los resultados de las frases\n",
        "   print(\"FRASE\") \n",
        "   print(\"La frase original\", test_data)    \n",
        "   print(\"La frase original preprocesada\", inputs)\n",
        "   print(\"Salida del modelo\", tag_scores)\n",
        "   print(\"Valores máximos e índices\", max_values(tag_scores))    \n",
        "    \n",
        "print(\"Clases\")\n",
        "print(tag_to_ix)\n",
        "\n",
        "#Frase 1\n",
        "# Las palabras en una oración se pueden etiquetar de tres formas.\n",
        "# La primera oración tiene 3 palabras \"El perro juega\"\n",
        "# por eso el tensor de salida tiene 3 elementos. \n",
        "# Cada elemento es un vector de probabilidad de estar asociada a una clase. \n",
        "# Es decir hay que calcular la posición del valor máximo. \n",
        "#   Ejemplo 1: \"El perro juega\" [\"DET\", \"NN\", \"V\"]\n",
        "# Ejemplo: salida 0, 1, 2 con {\"DET\": 0, \"NN\": 1, \"V\": 2} => DET, NN, V \n",
        "test_examples(test_data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NmaezBY4CXe",
        "outputId": "e4259e4a-59f3-45b7-bd2c-e26ff74c5f52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FRASE\n",
            "La frase original ['El', 'pájaro', 'alegre', 'canta', 'melodías', 'hermosas']\n",
            "La frase original preprocesada tensor([  0, 156, 157, 158, 159, 160])\n",
            "Salida del modelo tensor([[-9.4977e-04, -6.9671e+00, -1.1981e+01, -1.4436e+01],\n",
            "        [-1.2067e+01, -1.1533e-03, -1.8914e+01, -6.7707e+00],\n",
            "        [-9.3166e+00, -4.7764e+00, -7.2982e+00, -9.2352e-03],\n",
            "        [-1.2215e+01, -9.4336e+00, -1.4378e-01, -2.0111e+00],\n",
            "        [-6.3779e+00, -5.5018e+00, -3.4360e+00, -3.8710e-02],\n",
            "        [-6.1086e+00, -9.4115e+00, -5.6043e+00, -6.0057e-03]])\n",
            "Valores máximos e índices (tensor([-0.0009, -0.0012, -0.0092, -0.1438, -0.0387, -0.0060]), tensor([0, 1, 3, 2, 3, 3]))\n",
            "valor de las etiquetas {'DET': 0, 'NN': 1, 'V': 2, 'ADJ': 3}\n"
          ]
        }
      ],
      "source": [
        "#Frase 2\n",
        "test_examples(test_data[0][0])\n",
        "print(\"valor de las etiquetas\", tag_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ-XPjku4CXe",
        "outputId": "9c3a73b4-b176-4330-cedd-2decc72a1efe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FRASE\n",
            "La frase original ['La', 'música', 'suave', 'suena', 'relajante']\n",
            "La frase original preprocesada tensor([  4, 165,  10, 121, 166])\n",
            "Salida del modelo tensor([[-5.7335e-04, -7.4752e+00, -1.2082e+01, -1.4449e+01],\n",
            "        [-1.3905e+01, -2.2060e-03, -1.9453e+01, -6.1181e+00],\n",
            "        [-5.5906e+00, -4.3287e+00, -4.8420e+00, -2.5122e-02],\n",
            "        [-7.7758e+00, -1.1870e+01, -6.6100e-03, -5.0895e+00],\n",
            "        [-7.4717e+00, -1.3817e+01, -4.7315e-03, -5.4846e+00]])\n",
            "Valores máximos e índices (tensor([-0.0006, -0.0022, -0.0251, -0.0066, -0.0047]), tensor([0, 1, 3, 2, 2]))\n",
            "valor de las etiquetas {'DET': 0, 'NN': 1, 'V': 2, 'ADJ': 3}\n"
          ]
        }
      ],
      "source": [
        "# Otra prueba\n",
        "test_examples(test_data[2][0])\n",
        "print(\"valor de las etiquetas\", tag_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_tags = [[tag_to_ix[tag] for tag in tags] for words, tags in test_data]\n",
        "print(true_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7aLuLGIgTy6",
        "outputId": "70bb4509-7676-4b64-9ea2-eb26ae63a99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 3, 2, 1, 3], [0, 1, 3, 2, 0, 0, 1, 3], [0, 1, 3, 2, 3], [0, 1, 3, 2, 1, 0, 3], [0, 1, 3, 2, 0, 1], [0, 1, 3, 2, 0, 1, 3], [0, 1, 3, 2, 1, 0, 3], [0, 1, 3, 2, 0, 1, 3], [0, 1, 3, 2, 0, 0, 1, 3], [0, 1, 3, 2, 0, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "# Se recorre todos los datos de test_data\n",
        "for sentence, labels in test_data:\n",
        "   # print(\"sentence\", len(sentence))\n",
        "   # print(\"labels\", len(labels))\n",
        "    true_labels.extend(labels)\n",
        "\n",
        "# Aquí es pura magia, se asigna el tag a cada sentencia para que puedan ajustarse a los valores de los tensores\n",
        "true_labels = [tag_to_ix[tag] for sentence in test_data for tag in sentence[1]]\n",
        "print(true_labels)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmbvH_hvkZQ0",
        "outputId": "89e93bdf-4518-4494-9f5a-eb145eb314ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 3, 2, 1, 3, 0, 1, 3, 2, 0, 0, 1, 3, 0, 1, 3, 2, 3, 0, 1, 3, 2, 1, 0, 3, 0, 1, 3, 2, 0, 1, 0, 1, 3, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 3, 0, 1, 3, 2, 0, 1, 3, 0, 1, 3, 2, 0, 0, 1, 3, 0, 1, 3, 2, 0, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = []\n",
        "# Se recore cada valor de test_data\n",
        "for sentence, labels in test_data:\n",
        "   #print(\"sentence\", len(sentence))\n",
        "    #print(\"labels\", len(labels))\n",
        "\n",
        "    # Aquí es pura magia se retornan los valores maximos de los tensores que se tuvieron en las oraciones\n",
        "    predicted_labels.extend(max_values(model(prepare_sequence(sentence, word_to_ix)))[1])\n",
        "\n",
        "print(predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlGzFtGAkcH-",
        "outputId": "e6f81c8c-1efe-47ad-8218-ce4c664a3c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor(0), tensor(1), tensor(3), tensor(2), tensor(3), tensor(3), tensor(0), tensor(1), tensor(3), tensor(2), tensor(2), tensor(0), tensor(1), tensor(3), tensor(0), tensor(1), tensor(3), tensor(2), tensor(2), tensor(0), tensor(1), tensor(3), tensor(2), tensor(0), tensor(0), tensor(2), tensor(0), tensor(1), tensor(3), tensor(2), tensor(0), tensor(0), tensor(0), tensor(1), tensor(3), tensor(3), tensor(3), tensor(2), tensor(2), tensor(0), tensor(1), tensor(3), tensor(2), tensor(3), tensor(0), tensor(3), tensor(0), tensor(1), tensor(3), tensor(2), tensor(0), tensor(0), tensor(3), tensor(0), tensor(1), tensor(3), tensor(2), tensor(0), tensor(0), tensor(0), tensor(1), tensor(0), tensor(1), tensor(3), tensor(2), tensor(0), tensor(1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "# Se usa precision_recall_fscore_support para determinar la precision, exhaustividad y F1 en base a al average, true_labels y predicted_labels\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
        "# Se imprimen los resultados\n",
        "print(\"Precisión:\", precision)\n",
        "print(\"Exhaustividad:\", recall)\n",
        "print(\"F1:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjHvND0vkiaJ",
        "outputId": "daf962d1-fa3b-4225-e651-c0c4be14a317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión: 0.7880709671754448\n",
            "Exhaustividad: 0.7761194029850746\n",
            "F1: 0.7730661055167556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "1. Se logró agregar la nueva clase de etiqueta y generar un conjunto de datos más grande, lo que permitió mejorar el desempeño del modelo. La división del conjunto de datos en entrenamiento y prueba permitió una mejor evaluación del modelo.\n",
        "\n",
        "2. Es importante considerar al crear el conjunto de datos no contenga error en la asignacion de etiquetas en cuanto a el tipo y la cantidad ya que estos errores ca\n",
        "\n",
        "3. El modelo de clasificación alcanzó una precisión promedio de 78.8%, lo que indica que en promedio es capaz de clasificar correctamente el 78.8% de las palabras en las frases de prueba.\n",
        "\n",
        "4. La exhaustividad promedio del modelo fue del 77.6%, lo que significa que el modelo identificó correctamente el 77.6% de las palabras que realmente pertenecen a cada clase.\n",
        "\n",
        "5. El valor de F1, que combina la precisión y la exhaustividad, fue de 0.773, lo que sugiere que el modelo es razonablemente bueno para clasificar las palabras en las frases de prueba.\n",
        "\n"
      ],
      "metadata": {
        "id": "WWWnTuGfowWA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZjYZ9vfDfV9"
      },
      "source": [
        "# Referencias \n",
        "\n",
        "[1] Guthrie, R. (2017). Tutorial. Sequence Models and Long-Short Term Memory Networks. Recuperado de https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
        "\n",
        "[2] LeCun,Y., Bengio, Y.,  & Hinton, G. (2015). Deep learning. Nature, 521(7553):436.\n",
        "\n",
        "[3] Brownlee, J. (2017). What Are Word Embeddings for Text?. Recuperado de https://machinelearningmastery.com/what-are-word-embeddings/\n",
        "\n",
        "[4] Bishop, C (2006). Pattern Recognition and Machine Learning. Springer."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}